{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP - Multi-Layer Perceptron\n",
    "\n",
    "In this notebook, I create a deep learning model to predict the `diameter` and `albedo` values. Then save the model for use in `data-cleaning` notebook`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f73dbf04af0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.nn import LazyLinear, Dropout, ReLU, Sequential, LayerNorm\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "torch.manual_seed(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishrak/Documents/Asteroid-Mining-Analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 2.9995, 0.0956, 0.0641, 0.0000, 1.8861, 0.0000,\n",
       "        0.0000, 0.0000, 0.0342, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0211, 0.0000, 0.0000, 2.9773, 0.0000, 0.7055, 1.3559, 0.0000,\n",
       "        0.6901, 0.2212, 0.0000, 0.7959, 0.0000, 0.0000, 0.0000, 1.7026, 0.0000,\n",
       "        0.0000, 0.0000, 1.9092, 0.0000, 0.0000, 0.2701, 2.1247, 0.0000, 0.3357,\n",
       "        0.0000, 0.0852, 0.0000, 1.1907, 0.0000, 0.0000, 0.0000, 0.0000, 0.8020,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.8124, 0.7961, 0.0000, 0.0000, 0.0729,\n",
       "        0.0000], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleBlock(torch.nn.Module):\n",
    "    def __init__(self, num_output: int, dropout: float):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = Sequential(\n",
    "            LazyLinear(num_output),\n",
    "            LayerNorm(num_output),\n",
    "            ReLU(),\n",
    "            Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "\n",
    "block = SimpleBlock(64, 0.2)\n",
    "test = torch.arange(60, dtype=torch.float32)\n",
    "block(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Block(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, num_output_list: List[int], dropout_list: List[float], num_output: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = [\n",
    "            SimpleBlock(no, d) for no, d in zip(num_output_list, dropout_list)\n",
    "        ]\n",
    "\n",
    "        self.layer_out = LazyLinear(num_output)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        output = X\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            output = torch.concat([output, layer(X)])\n",
    "        \n",
    "        return self.layer_out(output)\n",
    "\n",
    "\n",
    "block = Block(num_output_list=[32, 16, 16], dropout_list=[0.3, 0.2, 0.2], num_output=64)\n",
    "block(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-25.0437, -13.5082], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n: int, block_io_shape: int = 64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_in = LazyLinear(block_io_shape)\n",
    "\n",
    "        self.layers = [\n",
    "            Block(\n",
    "                num_output_list=[32, 16, 16],\n",
    "                dropout_list=[0.3, 0.2, 0.2],\n",
    "                num_output=block_io_shape,\n",
    "            )\n",
    "            for _ in range(n)\n",
    "        ]\n",
    "        \n",
    "        self.output_layer = LazyLinear(2)\n",
    "\n",
    "        self.apply(self._init)\n",
    "\n",
    "        self.loss = MSELoss()\n",
    "\n",
    "    def _init(self, module):\n",
    "        if type(module) is torch.nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        output = self.layer_in(X)\n",
    "\n",
    "        for l in self.layers:\n",
    "            output = l(output) + output\n",
    "\n",
    "        return self.output_layer(output)\n",
    "\n",
    "    def loss(self, y, pred):\n",
    "        return self.loss(y, pred)\n",
    "\n",
    "\n",
    "mlp = MLP(3)\n",
    "mlp(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10707/4156258339.py:1: DtypeWarning: Columns (9,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/Asteroid_Imputed.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(839714, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Asteroid_Imputed.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'data_arc',\n",
       "       'condition_code', 'n_obs_used', 'H', 'neo', 'pha', 'diameter', 'albedo',\n",
       "       'moid', 'class', 'n', 'per', 'ma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df.condition_code == 'D') | (df.condition_code == 'E')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition_code = df.condition_code.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing numerical columns using min-max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'data_arc', 'n_obs_used',\n",
      "       'H', 'diameter', 'albedo', 'moid', 'n', 'per', 'ma'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = [\"pha\", \"neo\", \"condition_code\", \"class\"]\n",
    "numerical_columns = df.columns[~df.columns.isin(categorical_columns)]\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before **Min-Max Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't be normalizing the values for `diameter` and `albedo`, because I want the deep learning model to predict these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = numerical_columns.drop([\"diameter\", \"albedo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>moid</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614610</th>\n",
       "      <td>3.198038</td>\n",
       "      <td>0.308327</td>\n",
       "      <td>11.802038</td>\n",
       "      <td>187.640740</td>\n",
       "      <td>135.594892</td>\n",
       "      <td>1.826876</td>\n",
       "      <td>3.938094</td>\n",
       "      <td>5.454249</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.835575</td>\n",
       "      <td>0.172337</td>\n",
       "      <td>2088.929536</td>\n",
       "      <td>290.191970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395427</th>\n",
       "      <td>2.288280</td>\n",
       "      <td>0.073797</td>\n",
       "      <td>3.467121</td>\n",
       "      <td>102.449277</td>\n",
       "      <td>295.556111</td>\n",
       "      <td>2.457067</td>\n",
       "      <td>2.588706</td>\n",
       "      <td>4.800755</td>\n",
       "      <td>7110.0</td>\n",
       "      <td>121</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1.466270</td>\n",
       "      <td>0.284735</td>\n",
       "      <td>1264.335197</td>\n",
       "      <td>46.269512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399609</th>\n",
       "      <td>3.209218</td>\n",
       "      <td>0.209471</td>\n",
       "      <td>10.722528</td>\n",
       "      <td>346.063768</td>\n",
       "      <td>76.635257</td>\n",
       "      <td>2.010219</td>\n",
       "      <td>3.759093</td>\n",
       "      <td>4.183545</td>\n",
       "      <td>5321.0</td>\n",
       "      <td>202</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1.053570</td>\n",
       "      <td>0.171437</td>\n",
       "      <td>2099.893013</td>\n",
       "      <td>244.960696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               a         e          i          om           w         q  \\\n",
       "614610  3.198038  0.308327  11.802038  187.640740  135.594892  1.826876   \n",
       "395427  2.288280  0.073797   3.467121  102.449277  295.556111  2.457067   \n",
       "399609  3.209218  0.209471  10.722528  346.063768   76.635257  2.010219   \n",
       "\n",
       "              ad     per_y  data_arc  n_obs_used     H      moid         n  \\\n",
       "614610  3.938094  5.454249      39.0          36  16.5  0.835575  0.172337   \n",
       "395427  2.588706  4.800755    7110.0         121  17.8  1.466270  0.284735   \n",
       "399609  3.759093  4.183545    5321.0         202  16.4  1.053570  0.171437   \n",
       "\n",
       "                per          ma  \n",
       "614610  2088.929536  290.191970  \n",
       "395427  1264.335197   46.269512  \n",
       "399609  2099.893013  244.960696  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[numerical_columns].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_columns:\n",
    "    values = df_processed[column].values.reshape(-1, 1)\n",
    "    df_processed[column] = MinMaxScaler().fit_transform(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After **Min-Max Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>moid</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127971</th>\n",
       "      <td>0.971667</td>\n",
       "      <td>0.063012</td>\n",
       "      <td>0.043090</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.644162</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.084958</td>\n",
       "      <td>0.067789</td>\n",
       "      <td>0.483965</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.114174</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.691284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580755</th>\n",
       "      <td>0.971673</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>0.028716</td>\n",
       "      <td>0.791756</td>\n",
       "      <td>0.044079</td>\n",
       "      <td>0.032894</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.516035</td>\n",
       "      <td>0.021354</td>\n",
       "      <td>0.079457</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.181094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716423</th>\n",
       "      <td>0.971674</td>\n",
       "      <td>0.323119</td>\n",
       "      <td>0.051522</td>\n",
       "      <td>0.476163</td>\n",
       "      <td>0.533100</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.511458</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.075963</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.706963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               a         e         i        om         w         q        ad  \\\n",
       "127971  0.971667  0.063012  0.043090  0.999725  0.644162  0.026015  0.000361   \n",
       "580755  0.971673  0.043696  0.028716  0.791756  0.044079  0.032894  0.000466   \n",
       "716423  0.971674  0.323119  0.051522  0.476163  0.533100  0.015300  0.000410   \n",
       "\n",
       "           per_y  data_arc  n_obs_used         H      moid         n  \\\n",
       "127971  0.000027  0.084958    0.067789  0.483965  0.014599  0.114174   \n",
       "580755  0.000022  0.000165    0.000858  0.516035  0.021354  0.079457   \n",
       "716423  0.000020  0.001623    0.005899  0.511458  0.003746  0.075963   \n",
       "\n",
       "             per        ma  \n",
       "127971  0.000019  0.691284  \n",
       "580755  0.000029  0.181094  \n",
       "716423  0.000030  0.706963  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[numerical_columns].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839559, 49)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed = pd.get_dummies(\n",
    "    df_processed,\n",
    "    columns=categorical_columns,\n",
    "    dummy_na=True,\n",
    ")\n",
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'data_arc', 'n_obs_used',\n",
       "       'H', 'diameter', 'albedo', 'moid', 'n', 'per', 'ma', 'pha_N', 'pha_Y',\n",
       "       'pha_nan', 'neo_N', 'neo_Y', 'neo_nan', 'condition_code_0.0',\n",
       "       'condition_code_1.0', 'condition_code_2.0', 'condition_code_3.0',\n",
       "       'condition_code_4.0', 'condition_code_5.0', 'condition_code_6.0',\n",
       "       'condition_code_7.0', 'condition_code_8.0', 'condition_code_9.0',\n",
       "       'condition_code_nan', 'class_AMO', 'class_APO', 'class_AST',\n",
       "       'class_ATE', 'class_CEN', 'class_HYA', 'class_IEO', 'class_IMB',\n",
       "       'class_MBA', 'class_MCA', 'class_OMB', 'class_PAA', 'class_TJN',\n",
       "       'class_TNO', 'class_nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll split them into two sets. \n",
    "\n",
    "* **Set 1**: Diameter and albedo are both not null. These will be used for training purposes.\n",
    "\n",
    "* **Set 2**: Diameter or albedo are null. These will be used for inferencing purposes. The model will predict their values given the other column values, and then I'll use the predicted values to impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples for training purposes: 136406\n",
      "Number of examples for inference purposes: 839559\n"
     ]
    }
   ],
   "source": [
    "set_1 = df_processed[df_processed.diameter.notnull() & df_processed.albedo.notnull()]\n",
    "set_2 = df_processed[~df_processed.isin(set_1)]\n",
    "\n",
    "print(f\"Number of examples for training purposes: {set_1.shape[0]}\")\n",
    "print(f\"Number of examples for inference purposes: {set_2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now split the first set into\n",
    "\n",
    "1. **Training set**: Used specifically to train the model.\n",
    "2. **Validation set**: Used to check model's performance on unseen data.\n",
    "3. **Test set**: Used to check generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((122765, 49), (6821, 49), (6820, 49))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = set_1.sample(frac=0.9, random_state=29)\n",
    "valid = set_1[~set_1.isin(train)].dropna()\n",
    "test = valid.sample(frac=0.5)\n",
    "valid = valid[~valid.isin(test)].dropna()\n",
    "\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set X shape: (122765, 47)\n",
      "Validation set X shape: (6820, 47)\n",
      "Test set X shape: (6821, 47)\n"
     ]
    }
   ],
   "source": [
    "train_X = train.drop(columns=[\"diameter\", \"albedo\"]).values.astype(np.float64)\n",
    "test_X = valid.drop(columns=[\"diameter\", \"albedo\"]).values.astype(np.float64)\n",
    "valid_X = test.drop(columns=[\"diameter\", \"albedo\"]).values.astype(np.float64)\n",
    "\n",
    "print(f\"Training set X shape: {train_X.shape}\")\n",
    "print(f\"Validation set X shape: {valid_X.shape}\")\n",
    "print(f\"Test set X shape: {test_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Y shape: (122765, 2)\n",
      "Validation set Y shape: (6821, 2)\n",
      "Test set Y shape: (6820, 2)\n"
     ]
    }
   ],
   "source": [
    "train_Y = train[[\"diameter\", \"albedo\"]].values.astype(np.float64)\n",
    "valid_Y = valid[[\"diameter\", \"albedo\"]].values.astype(np.float64)\n",
    "test_Y = test[[\"diameter\", \"albedo\"]].values.astype(np.float64)\n",
    "\n",
    "print(f\"Training set Y shape: {train_Y.shape}\")\n",
    "print(f\"Validation set Y shape: {valid_Y.shape}\")\n",
    "print(f\"Test set Y shape: {test_Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, valid, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Data Loader for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "VALIDATION_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(train_X)\n",
    "train_Y = torch.tensor(train_Y)\n",
    "\n",
    "valid_X = torch.tensor(valid_X)\n",
    "valid_Y = torch.tensor(valid_Y)\n",
    "\n",
    "test_X = torch.tensor(test_X)\n",
    "test_Y = torch.tensor(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    list(zip(train_X, train_Y)),\n",
    "    shuffle=True,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    list(zip(valid_X, valid_Y)),\n",
    "    shuffle=True,\n",
    "    batch_size=VALIDATION_BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_X, test_Y)),\n",
    "    shuffle=True,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 47]) torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
