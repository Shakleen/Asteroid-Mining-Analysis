{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP - Multi-Layer Perceptron\n",
    "\n",
    "In this notebook, I create a deep learning model to predict the `diameter` and `albedo` values. Then save the model for use in `data-cleaning` notebook`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5d6531cad0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from torch.nn import LazyLinear, Dropout, ReLU, Sequential, LayerNorm\n",
    "from torch.nn import HuberLoss\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishrak/Documents/Asteroid-Mining-Analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4527e-01,\n",
       "         2.4261e-01, 4.9356e-01, 0.0000e+00, 0.0000e+00, 7.1284e-01, 0.0000e+00,\n",
       "         6.8023e-01, 0.0000e+00, 8.1596e-01, 3.1018e-01, 0.0000e+00, 1.4151e+00,\n",
       "         1.8673e+00, 9.4119e-01, 0.0000e+00, 1.8731e+00, 1.3865e+00, 0.0000e+00,\n",
       "         0.0000e+00, 6.8817e-01, 6.1017e-01, 0.0000e+00, 3.4964e-01, 0.0000e+00,\n",
       "         1.4606e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4808e+00, 0.0000e+00,\n",
       "         1.9103e-01, 2.7640e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3514e+00,\n",
       "         0.0000e+00, 5.9760e-01, 4.5625e-01, 0.0000e+00, 1.9209e-01, 6.2832e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.5578e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1210e-01,\n",
       "         1.1073e+00, 1.2956e+00, 1.9248e+00, 8.8449e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4441e-01,\n",
       "         7.1475e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9410e-02, 0.0000e+00,\n",
       "         4.7923e-01, 4.4993e-01, 3.8552e-01, 0.0000e+00, 6.9334e-01, 5.6889e-01,\n",
       "         2.2249e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7519e-01, 2.4518e+00,\n",
       "         6.5209e-01, 6.0416e-01, 5.2471e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         8.8232e-01, 0.0000e+00, 1.3417e+00, 5.2146e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 8.7273e-02, 9.3160e-01, 0.0000e+00, 0.0000e+00, 2.7911e+00,\n",
       "         0.0000e+00, 8.5367e-01, 2.8114e-01, 0.0000e+00, 7.5224e-01, 5.6506e-01,\n",
       "         0.0000e+00, 0.0000e+00, 8.3225e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.2033e-01, 0.0000e+00, 8.7364e-01, 2.4762e-01, 9.4908e-01,\n",
       "         0.0000e+00, 4.8532e-01, 1.5300e+00, 3.7460e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4071e-01,\n",
       "         7.9818e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.2462e-01, 5.0173e-01, 2.8419e-01, 0.0000e+00, 9.1352e-01, 3.7429e-01,\n",
       "         2.2471e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5006e-01, 2.4252e+00,\n",
       "         0.0000e+00, 5.7151e-01, 4.9367e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         7.3732e-01, 1.7576e+00, 1.3014e+00, 6.3064e-01, 1.6393e+00, 0.0000e+00,\n",
       "         0.0000e+00, 4.4753e-02, 1.1084e+00, 0.0000e+00, 0.0000e+00, 2.8170e+00,\n",
       "         0.0000e+00, 8.8756e-01, 2.3689e-01, 0.0000e+00, 8.5356e-01, 5.3778e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.0291e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0349e-01, 0.0000e+00, 9.9793e-01,\n",
       "         1.5774e+00, 3.0043e-01, 1.4085e+00, 2.5657e-01],\n",
       "        [0.0000e+00, 3.5630e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3880e-01,\n",
       "         8.3142e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 5.2235e-01, 2.4072e-01, 0.0000e+00, 1.0042e+00, 2.9124e-01,\n",
       "         2.2509e+00, 1.6561e+00, 0.0000e+00, 8.6777e-01, 0.0000e+00, 2.4080e+00,\n",
       "         0.0000e+00, 5.5631e-01, 4.7935e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.7429e-01, 0.0000e+00, 1.2812e+00, 6.7516e-01, 1.6331e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.6697e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8209e+00,\n",
       "         0.0000e+00, 8.9967e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2494e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.1097e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.0141e-01, 0.0000e+00, 7.7189e-01, 1.6111e-01, 0.0000e+00,\n",
       "         1.5955e+00, 0.0000e+00, 0.0000e+00, 2.0612e-01],\n",
       "        [0.0000e+00, 4.1645e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3766e-01,\n",
       "         8.4917e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.8703e-01, 5.3335e-01, 2.1668e-01, 0.0000e+00, 1.0534e+00, 2.4539e-01,\n",
       "         2.2516e+00, 1.6736e+00, 0.0000e+00, 8.2289e-01, 2.1960e-03, 2.3970e+00,\n",
       "         1.0118e+00, 5.4761e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.3922e-01, 1.7128e+00, 1.2693e+00, 6.9921e-01, 1.6287e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.6753e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8214e+00,\n",
       "         0.0000e+00, 9.0577e-01, 2.0690e-01, 0.0000e+00, 9.1600e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.1532e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5404e-01, 0.0000e+00, 1.0254e+00,\n",
       "         1.6044e+00, 1.7820e-01, 1.3227e+00, 1.7825e-01],\n",
       "        [0.0000e+00, 4.5437e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3691e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.7841e-01, 5.4019e-01, 2.0143e-01, 0.0000e+00, 1.0843e+00, 2.1637e-01,\n",
       "         2.2515e+00, 1.6842e+00, 0.0000e+00, 7.9434e-01, 0.0000e+00, 2.3895e+00,\n",
       "         1.0427e+00, 5.4198e-01, 4.6591e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.1692e-01, 1.7019e+00, 1.2615e+00, 7.1425e-01, 1.6255e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0465e-02, 1.2433e+00, 0.0000e+00, 0.0000e+00, 2.8210e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1276e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.1805e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.9580e-01, 0.0000e+00, 7.4258e-01, 1.3759e-01, 1.0311e+00,\n",
       "         0.0000e+00, 1.5071e-01, 1.3028e+00, 1.6060e-01],\n",
       "        [0.0000e+00, 4.8044e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3638e-01,\n",
       "         8.6771e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.7243e-01, 5.4484e-01, 1.9090e-01, 0.0000e+00, 1.1054e+00, 1.9635e-01,\n",
       "         2.2513e+00, 1.6914e+00, 0.0000e+00, 7.7459e-01, 0.0000e+00, 2.3841e+00,\n",
       "         1.0638e+00, 5.3805e-01, 4.6223e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         6.0148e-01, 0.0000e+00, 1.2560e+00, 7.2454e-01, 1.6232e+00, 0.0000e+00,\n",
       "         0.0000e+00, 6.1322e-03, 1.2599e+00, 0.0000e+00, 0.0000e+00, 2.8204e+00,\n",
       "         0.0000e+00, 9.1183e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0941e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.9427e-01, 0.0000e+00, 0.0000e+00, 1.3128e-01, 1.0349e+00,\n",
       "         1.6132e+00, 1.3175e-01, 1.2890e+00, 1.4843e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         8.7314e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.6805e-01, 5.4821e-01, 1.8320e-01, 0.0000e+00, 1.1208e+00, 1.8171e-01,\n",
       "         2.2509e+00, 1.6965e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3801e+00,\n",
       "         1.0792e+00, 0.0000e+00, 4.5951e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         5.9018e-01, 1.6885e+00, 0.0000e+00, 7.3202e-01, 1.6213e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.9659e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8199e+00,\n",
       "         0.0000e+00, 9.1355e-01, 1.9189e-01, 0.0000e+00, 0.0000e+00, 5.0694e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.2128e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.9313e-01, 0.0000e+00, 7.2875e-01, 1.2667e-01, 1.0376e+00,\n",
       "         1.6156e+00, 1.1789e-01, 1.2788e+00, 1.3952e-01]], device='cuda:0',\n",
       "       grad_fn=<NativeDropoutBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleBlock(torch.nn.Module):\n",
    "    def __init__(self, num_output: int, dropout: float, device: str = \"cuda\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = Sequential(\n",
    "            LazyLinear(num_output, device=device),\n",
    "            LayerNorm(num_output, device=device),\n",
    "            ReLU(),\n",
    "            Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def __call__(self, X):\n",
    "        return self.net(X)\n",
    "\n",
    "\n",
    "block = SimpleBlock(64, 0.2, device=device)\n",
    "test = torch.arange(64, dtype=torch.float32).reshape(-1, 8).to(device)\n",
    "block(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Block(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_output_list: List[int],\n",
    "        dropout_list: List[float],\n",
    "        num_output: int,\n",
    "        device: str = \"cuda\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = [\n",
    "            SimpleBlock(no, d, device) for no, d in zip(num_output_list, dropout_list)\n",
    "        ]\n",
    "\n",
    "        self.layer_out = LazyLinear(num_output, device=device)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        output = X\n",
    "\n",
    "        for layer in self.layers:\n",
    "            output = torch.concat([output, layer(X)], axis=1)\n",
    "\n",
    "        return self.layer_out(output)\n",
    "\n",
    "\n",
    "block = Block(num_output_list=[32, 16, 16], dropout_list=[0.3, 0.2, 0.2], num_output=64, device=device)\n",
    "block(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -2.5064,  -1.2346],\n",
       "        [ -5.5732,  -3.1250],\n",
       "        [ -8.5703,  -4.5417],\n",
       "        [-11.8984,  -5.7778],\n",
       "        [-15.1231,  -7.5824],\n",
       "        [-17.9572,  -8.6474],\n",
       "        [-21.2816, -10.4809],\n",
       "        [-24.2204, -11.7324]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n: int,\n",
    "        num_output_list: List[int],\n",
    "        dropout_list: List[int],\n",
    "        block_io_shape: int = 64,\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_in = LazyLinear(block_io_shape, device=device)\n",
    "\n",
    "        self.layers = [\n",
    "            Block(\n",
    "                num_output_list=num_output_list,\n",
    "                dropout_list=dropout_list,\n",
    "                num_output=block_io_shape,\n",
    "            )\n",
    "            for _ in range(n)\n",
    "        ]\n",
    "\n",
    "        self.output_layer = LazyLinear(2, device=device)\n",
    "\n",
    "        self.apply(self._init)\n",
    "\n",
    "        self.mse_loss = HuberLoss()\n",
    "\n",
    "    def _init(self, module):\n",
    "        if type(module) is torch.nn.Linear:\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        output = self.layer_in(X)\n",
    "\n",
    "        for l in self.layers:\n",
    "            output = l(output) + output\n",
    "\n",
    "        return self.output_layer(output)\n",
    "\n",
    "    def loss(self, y, pred):\n",
    "        return self.mse_loss(y, pred)\n",
    "\n",
    "\n",
    "mlp = MLP(3, num_output_list=[32, 16, 16], dropout_list=[0.3, 0.2, 0.2], device=device)\n",
    "mlp(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp, test, block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7098/4156258339.py:1: DtypeWarning: Columns (9,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/Asteroid_Imputed.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(839714, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Asteroid_Imputed.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'data_arc',\n",
       "       'condition_code', 'n_obs_used', 'H', 'neo', 'pha', 'diameter', 'albedo',\n",
       "       'moid', 'class', 'n', 'per', 'ma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df.condition_code == 'D') | (df.condition_code == 'E')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition_code = df.condition_code.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing numerical columns using min-max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'data_arc', 'n_obs_used',\n",
      "       'H', 'diameter', 'albedo', 'moid', 'n', 'per', 'ma'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = [\"pha\", \"neo\", \"condition_code\", \"class\"]\n",
    "numerical_columns = df.columns[~df.columns.isin(categorical_columns)]\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before **Min-Max Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't be normalizing the values for `diameter` and `albedo`, because I want the deep learning model to predict these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = numerical_columns.drop([\"diameter\", \"albedo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>moid</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>474041</th>\n",
       "      <td>2.623381</td>\n",
       "      <td>0.030128</td>\n",
       "      <td>15.429898</td>\n",
       "      <td>90.119096</td>\n",
       "      <td>309.321053</td>\n",
       "      <td>5.164125</td>\n",
       "      <td>2.696228</td>\n",
       "      <td>4.280620</td>\n",
       "      <td>3209.00</td>\n",
       "      <td>96</td>\n",
       "      <td>16.700</td>\n",
       "      <td>4.195230</td>\n",
       "      <td>0.231959</td>\n",
       "      <td>1551.995156</td>\n",
       "      <td>151.953110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757496</th>\n",
       "      <td>2.612485</td>\n",
       "      <td>0.167968</td>\n",
       "      <td>4.622640</td>\n",
       "      <td>20.160320</td>\n",
       "      <td>284.182470</td>\n",
       "      <td>2.107553</td>\n",
       "      <td>3.108307</td>\n",
       "      <td>5.487518</td>\n",
       "      <td>3557.54</td>\n",
       "      <td>25</td>\n",
       "      <td>16.811</td>\n",
       "      <td>1.102941</td>\n",
       "      <td>0.233412</td>\n",
       "      <td>1542.336822</td>\n",
       "      <td>162.250462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381962</th>\n",
       "      <td>3.082989</td>\n",
       "      <td>0.064013</td>\n",
       "      <td>10.494348</td>\n",
       "      <td>5.944069</td>\n",
       "      <td>328.582692</td>\n",
       "      <td>2.901878</td>\n",
       "      <td>3.507587</td>\n",
       "      <td>3.742927</td>\n",
       "      <td>4123.00</td>\n",
       "      <td>107</td>\n",
       "      <td>16.400</td>\n",
       "      <td>1.898150</td>\n",
       "      <td>0.182073</td>\n",
       "      <td>1977.226312</td>\n",
       "      <td>350.458740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               a         e          i         om           w         q  \\\n",
       "474041  2.623381  0.030128  15.429898  90.119096  309.321053  5.164125   \n",
       "757496  2.612485  0.167968   4.622640  20.160320  284.182470  2.107553   \n",
       "381962  3.082989  0.064013  10.494348   5.944069  328.582692  2.901878   \n",
       "\n",
       "              ad     per_y  data_arc  n_obs_used       H      moid         n  \\\n",
       "474041  2.696228  4.280620   3209.00          96  16.700  4.195230  0.231959   \n",
       "757496  3.108307  5.487518   3557.54          25  16.811  1.102941  0.233412   \n",
       "381962  3.507587  3.742927   4123.00         107  16.400  1.898150  0.182073   \n",
       "\n",
       "                per          ma  \n",
       "474041  1551.995156  151.953110  \n",
       "757496  1542.336822  162.250462  \n",
       "381962  1977.226312  350.458740  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[numerical_columns].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_columns:\n",
    "    values = df_processed[column].values.reshape(-1, 1)\n",
    "    df_processed[column] = MinMaxScaler().fit_transform(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After **Min-Max Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>moid</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>737743</th>\n",
       "      <td>0.971669</td>\n",
       "      <td>0.118442</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>0.243951</td>\n",
       "      <td>0.368326</td>\n",
       "      <td>0.031756</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.067829</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>0.555335</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.098652</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.186316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355844</th>\n",
       "      <td>0.971671</td>\n",
       "      <td>0.142601</td>\n",
       "      <td>0.038003</td>\n",
       "      <td>0.187247</td>\n",
       "      <td>0.806842</td>\n",
       "      <td>0.022292</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.065256</td>\n",
       "      <td>0.015553</td>\n",
       "      <td>0.518950</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.088616</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.293588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837033</th>\n",
       "      <td>0.971658</td>\n",
       "      <td>0.291284</td>\n",
       "      <td>0.062758</td>\n",
       "      <td>0.098827</td>\n",
       "      <td>0.039972</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.009654</td>\n",
       "      <td>0.793003</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.233819</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.145772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               a         e         i        om         w         q        ad  \\\n",
       "737743  0.971669  0.118442  0.017659  0.243951  0.368326  0.031756  0.000398   \n",
       "355844  0.971671  0.142601  0.038003  0.187247  0.806842  0.022292  0.000436   \n",
       "837033  0.971658  0.291284  0.062758  0.098827  0.039972  0.005308  0.000188   \n",
       "\n",
       "           per_y  data_arc  n_obs_used         H      moid         n  \\\n",
       "737743  0.000021  0.067829    0.009224  0.555335  0.020320  0.098652   \n",
       "355844  0.000025  0.065256    0.015553  0.518950  0.010945  0.088616   \n",
       "837033  0.001585  0.000096    0.009654  0.793003  0.000092  0.233819   \n",
       "\n",
       "             per        ma  \n",
       "737743  0.000023  0.186316  \n",
       "355844  0.000025  0.293588  \n",
       "837033  0.000008  0.145772  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed[numerical_columns].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encode categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(839559, 49)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed = pd.get_dummies(\n",
    "    df_processed,\n",
    "    columns=categorical_columns,\n",
    "    dummy_na=True,\n",
    ")\n",
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'data_arc', 'n_obs_used',\n",
       "       'H', 'diameter', 'albedo', 'moid', 'n', 'per', 'ma', 'pha_N', 'pha_Y',\n",
       "       'pha_nan', 'neo_N', 'neo_Y', 'neo_nan', 'condition_code_0.0',\n",
       "       'condition_code_1.0', 'condition_code_2.0', 'condition_code_3.0',\n",
       "       'condition_code_4.0', 'condition_code_5.0', 'condition_code_6.0',\n",
       "       'condition_code_7.0', 'condition_code_8.0', 'condition_code_9.0',\n",
       "       'condition_code_nan', 'class_AMO', 'class_APO', 'class_AST',\n",
       "       'class_ATE', 'class_CEN', 'class_HYA', 'class_IEO', 'class_IMB',\n",
       "       'class_MBA', 'class_MCA', 'class_OMB', 'class_PAA', 'class_TJN',\n",
       "       'class_TNO', 'class_nan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll split them into two sets. \n",
    "\n",
    "* **Set 1**: Diameter and albedo are both not null. These will be used for training purposes.\n",
    "\n",
    "* **Set 2**: Diameter or albedo are null. These will be used for inferencing purposes. The model will predict their values given the other column values, and then I'll use the predicted values to impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples for training purposes: 136406\n",
      "Number of examples for inference purposes: 839559\n"
     ]
    }
   ],
   "source": [
    "set_1 = df_processed[df_processed.diameter.notnull() & df_processed.albedo.notnull()]\n",
    "set_2 = df_processed[~df_processed.isin(set_1)]\n",
    "\n",
    "print(f\"Number of examples for training purposes: {set_1.shape[0]}\")\n",
    "print(f\"Number of examples for inference purposes: {set_2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll now split the first set into\n",
    "\n",
    "1. **Training set**: Used specifically to train the model.\n",
    "2. **Validation set**: Used to check model's performance on unseen data.\n",
    "3. **Test set**: Used to check generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((122765, 49), (6821, 49), (6820, 49))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = set_1.sample(frac=0.9, random_state=29)\n",
    "valid = set_1[~set_1.isin(train)].dropna()\n",
    "test = valid.sample(frac=0.5)\n",
    "valid = valid[~valid.isin(test)].dropna()\n",
    "\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set X shape: (122765, 47)\n",
      "Validation set X shape: (6820, 47)\n",
      "Test set X shape: (6821, 47)\n"
     ]
    }
   ],
   "source": [
    "train_X = train.drop(columns=[\"diameter\", \"albedo\"]).values.astype(np.float64)\n",
    "test_X = valid.drop(columns=[\"diameter\", \"albedo\"]).values.astype(np.float64)\n",
    "valid_X = test.drop(columns=[\"diameter\", \"albedo\"]).values.astype(np.float64)\n",
    "\n",
    "print(f\"Training set X shape: {train_X.shape}\")\n",
    "print(f\"Validation set X shape: {valid_X.shape}\")\n",
    "print(f\"Test set X shape: {test_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Y shape: (122765, 2)\n",
      "Validation set Y shape: (6821, 2)\n",
      "Test set Y shape: (6820, 2)\n"
     ]
    }
   ],
   "source": [
    "train_Y = train[[\"diameter\", \"albedo\"]].values.astype(np.float64)\n",
    "valid_Y = valid[[\"diameter\", \"albedo\"]].values.astype(np.float64)\n",
    "test_Y = test[[\"diameter\", \"albedo\"]].values.astype(np.float64)\n",
    "\n",
    "print(f\"Training set Y shape: {train_Y.shape}\")\n",
    "print(f\"Validation set Y shape: {valid_Y.shape}\")\n",
    "print(f\"Test set Y shape: {test_Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, valid, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Data Loader for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 256\n",
    "VALIDATION_BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(train_X, dtype=torch.float32)\n",
    "train_Y = torch.tensor(train_Y, dtype=torch.float32)\n",
    "\n",
    "valid_X = torch.tensor(valid_X, dtype=torch.float32)\n",
    "valid_Y = torch.tensor(valid_Y, dtype=torch.float32)\n",
    "\n",
    "test_X = torch.tensor(test_X, dtype=torch.float32)\n",
    "test_Y = torch.tensor(test_Y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(\n",
    "    list(zip(train_X, train_Y)),\n",
    "    shuffle=True,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    list(zip(valid_X, valid_Y)),\n",
    "    shuffle=True,\n",
    "    batch_size=VALIDATION_BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    list(zip(test_X, test_Y)),\n",
    "    shuffle=True,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from torch.optim import AdamW, lr_scheduler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(3, num_output_list=[256, 128, 64], dropout_list=[0.3, 0.2, 0.1], device=device)\n",
    "optimizer = AdamW(model.parameters(), lr=4e-6)\n",
    "scheduler = lr_scheduler.ExponentialLR(\n",
    "    optimizer,\n",
    "    gamma=0.9,\n",
    "    last_epoch=-1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 10\n",
    "min_eval_loss = float(\"inf\")\n",
    "early_stopping_hook = 0\n",
    "tracking_information = []\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "root_save_dir = \"model_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_train():\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for _, (X, y) in zip(\n",
    "        tqdm(range(len(train_loader)), desc=\"Training batch: ...\"),\n",
    "        train_loader,\n",
    "    ):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "\n",
    "        loss = model.loss(y, pred)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_validate():\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "\n",
    "    for _, batch in zip(\n",
    "        tqdm(range(len(valid_loader)), desc=\"Validating batch: ...\"),\n",
    "        valid_loader,\n",
    "    ):\n",
    "        X, y = batch\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = model.loss(y, pred)\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "    return valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tracking(epoch, train_loss, valid_loss):\n",
    "    tracking_information.append(\n",
    "        (\n",
    "            train_loss / len(train_loader),\n",
    "            valid_loss / len(valid_loader),\n",
    "            optimizer.param_groups[0][\"lr\"],\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Epoch: {} - Training loss: {} - Eval Loss: {} - LR: {}\".format(\n",
    "            epoch + 1,\n",
    "            train_loss / len(train_loader),\n",
    "            valid_loss / len(valid_loader),\n",
    "            optimizer.param_groups[0][\"lr\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...:   0%|          | 0/480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 313.81it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 759.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 - Training loss: 1.9524196463326613 - Eval Loss: 1.8300088290815 - LR: 4e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 292.02it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 753.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 - Training loss: 1.855955681949854 - Eval Loss: 1.7394157250722249 - LR: 3.6e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 293.60it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 747.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 - Training loss: 1.7765649527311325 - Eval Loss: 1.678665487854569 - LR: 3.24e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 276.36it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 749.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 - Training loss: 1.7085920783380668 - Eval Loss: 1.6101428270339966 - LR: 2.916e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 287.80it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 727.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 - Training loss: 1.6490216962993145 - Eval Loss: 1.558377257099858 - LR: 2.6244000000000002e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 286.72it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 713.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 - Training loss: 1.601439692080021 - Eval Loss: 1.5129952607331452 - LR: 2.36196e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 288.55it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 677.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 - Training loss: 1.5585725508630275 - Eval Loss: 1.472743617163764 - LR: 2.1257640000000003e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 288.66it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 739.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 - Training loss: 1.522910655538241 - Eval Loss: 1.4385069564536765 - LR: 1.9131876000000005e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 285.78it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 706.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 - Training loss: 1.4928836264957985 - Eval Loss: 1.4080841585441872 - LR: 1.7218688400000004e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 290.45it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 736.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 - Training loss: 1.4665721323341132 - Eval Loss: 1.3816477678440235 - LR: 1.5496819560000004e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 288.93it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 730.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 - Training loss: 1.4454419946918884 - Eval Loss: 1.3618855255621451 - LR: 1.3947137604000004e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 287.22it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 710.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 - Training loss: 1.4259742711981138 - Eval Loss: 1.3428672353426616 - LR: 1.2552423843600003e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 288.92it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 733.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 - Training loss: 1.4102259505540133 - Eval Loss: 1.340317483301516 - LR: 1.1297181459240003e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 290.68it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 716.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 - Training loss: 1.3964660704135894 - Eval Loss: 1.3205079347999007 - LR: 1.0167463313316002e-06\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 291.28it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 685.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 - Training loss: 1.3833566195021072 - Eval Loss: 1.303453712551682 - LR: 9.150716981984402e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 290.80it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 735.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 - Training loss: 1.3728491098930438 - Eval Loss: 1.2997339831458197 - LR: 8.235645283785962e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 296.16it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 732.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 - Training loss: 1.3630730702231328 - Eval Loss: 1.2864753007888794 - LR: 7.412080755407366e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 308.97it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 750.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 - Training loss: 1.3558967276165883 - Eval Loss: 1.2806999705455921 - LR: 6.67087267986663e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 292.59it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 732.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 - Training loss: 1.3483920802672704 - Eval Loss: 1.2772247283547014 - LR: 6.003785411879967e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 315.50it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 747.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 - Training loss: 1.3419010311365127 - Eval Loss: 1.273985864939513 - LR: 5.40340687069197e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 315.61it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 678.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 - Training loss: 1.3359517569343249 - Eval Loss: 1.265084566893401 - LR: 4.863066183622773e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 294.40it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 748.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 - Training loss: 1.3313128827760616 - Eval Loss: 1.2570603335345234 - LR: 4.3767595652604963e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 289.84it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 718.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 - Training loss: 1.3272870072474083 - Eval Loss: 1.254856197922318 - LR: 3.939083608734447e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 314.58it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 754.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 - Training loss: 1.3229388792067767 - Eval Loss: 1.2541517593242504 - LR: 3.5451752478610025e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 290.42it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 734.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 - Training loss: 1.3185556857536236 - Eval Loss: 1.2451316979196336 - LR: 3.1906577230749024e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 291.30it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 740.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 - Training loss: 1.3165630718072256 - Eval Loss: 1.2424207925796509 - LR: 2.871591950767412e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 291.08it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 716.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 - Training loss: 1.3140928149223328 - Eval Loss: 1.237779473816907 - LR: 2.584432755690671e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 291.70it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 705.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 - Training loss: 1.3108528794099887 - Eval Loss: 1.2383310066329107 - LR: 2.325989480121604e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 306.36it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 721.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 - Training loss: 1.3088704027235507 - Eval Loss: 1.2350970219682764 - LR: 2.0933905321094437e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 309.62it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 695.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 - Training loss: 1.306371617068847 - Eval Loss: 1.2368620921064306 - LR: 1.8840514788984994e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 295.10it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 736.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 - Training loss: 1.3052089499930541 - Eval Loss: 1.236525915287159 - LR: 1.6956463310086494e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 306.40it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 747.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 - Training loss: 1.3032809849828482 - Eval Loss: 1.2293030818303425 - LR: 1.5260816979077844e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 295.30it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 743.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 - Training loss: 1.3017661299556493 - Eval Loss: 1.233389766127975 - LR: 1.373473528117006e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 297.57it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 733.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 - Training loss: 1.3011733117202917 - Eval Loss: 1.2321699327892728 - LR: 1.2361261753053056e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 292.02it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 747.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 - Training loss: 1.2986623764038085 - Eval Loss: 1.2255642590699372 - LR: 1.1125135577747751e-07\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 295.09it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 744.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 - Training loss: 1.2985329491396744 - Eval Loss: 1.2258467254815277 - LR: 1.0012622019972976e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 288.64it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 704.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 - Training loss: 1.2979239941885075 - Eval Loss: 1.2349639137585957 - LR: 9.011359817975678e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 290.84it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 726.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 - Training loss: 1.2958340397725503 - Eval Loss: 1.2299008457748979 - LR: 8.110223836178111e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 295.02it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 727.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 - Training loss: 1.2952048242092133 - Eval Loss: 1.2252726091278925 - LR: 7.2992014525603e-08\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 298.46it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 740.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 - Training loss: 1.295137831941247 - Eval Loss: 1.2400945182199832 - LR: 6.56928130730427e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 299.60it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 738.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 - Training loss: 1.294790134454767 - Eval Loss: 1.228983512631169 - LR: 5.912353176573843e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 292.36it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 741.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 - Training loss: 1.2947616358598073 - Eval Loss: 1.2267610695627 - LR: 5.321117858916459e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 296.77it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 729.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 - Training loss: 1.2935409441590309 - Eval Loss: 1.2224979797999065 - LR: 4.7890060730248134e-08\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 288.34it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 735.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 - Training loss: 1.2931994049499431 - Eval Loss: 1.224821772840288 - LR: 4.310105465722332e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 293.04it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 732.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 - Training loss: 1.2928502682596446 - Eval Loss: 1.2337847462406866 - LR: 3.879094919150099e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 292.50it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 737.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 - Training loss: 1.2923749573528767 - Eval Loss: 1.2188196138099388 - LR: 3.491185427235089e-08\n",
      "Saved model to model_dir/resnet_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 289.92it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 723.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 - Training loss: 1.2924791979293029 - Eval Loss: 1.2201248341136508 - LR: 3.14206688451158e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 295.86it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 723.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 - Training loss: 1.2915183427433172 - Eval Loss: 1.2238414927765175 - LR: 2.8278601960604223e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 302.58it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 748.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 - Training loss: 1.290982134019335 - Eval Loss: 1.2223524274649444 - LR: 2.54507417645438e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 295.00it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 706.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 - Training loss: 1.2914825533827146 - Eval Loss: 1.2219454557807357 - LR: 2.290566758808942e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 294.25it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 750.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51 - Training loss: 1.2915317069739103 - Eval Loss: 1.219976665797057 - LR: 2.061510082928048e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 294.60it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 744.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52 - Training loss: 1.290595972041289 - Eval Loss: 1.2251980812461287 - LR: 1.855359074635243e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 313.44it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 739.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53 - Training loss: 1.290861088782549 - Eval Loss: 1.2224717449258875 - LR: 1.6698231671717187e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 302.00it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 728.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54 - Training loss: 1.2900120172649623 - Eval Loss: 1.2204801197405215 - LR: 1.502840850454547e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 291.68it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 739.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 - Training loss: 1.290819305429856 - Eval Loss: 1.2276332334235862 - LR: 1.3525567654090923e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 291.16it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 746.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 - Training loss: 1.2901231071601311 - Eval Loss: 1.2214339463799089 - LR: 1.2173010888681831e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batch: ...: 100%|██████████| 480/480 [00:01<00:00, 290.23it/s]\n",
      "Validating batch: ...: 100%|██████████| 27/27 [00:00<00:00, 733.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57 - Training loss: 1.2897595042983692 - Eval Loss: 1.2262143912138763 - LR: 1.0955709799813649e-08\n",
      "The training process has done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = epoch_train()\n",
    "    valid_loss = epoch_validate()\n",
    "\n",
    "    handle_tracking(epoch, train_loss, valid_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    if valid_loss < min_eval_loss:\n",
    "        model_save_file = os.path.join(root_save_dir, \"resnet_model\")\n",
    "        torch.save(model.state_dict(), model_save_file)\n",
    "        print(f\"Saved model to {model_save_file}\")\n",
    "        min_eval_loss = valid_loss\n",
    "        early_stopping_hook = 0\n",
    "    else:\n",
    "        early_stopping_hook += 1\n",
    "\n",
    "        if early_stopping_hook > patience:\n",
    "            break\n",
    "\n",
    "\n",
    "pickle.dump(\n",
    "    tracking_information,\n",
    "    open(os.path.join(root_save_dir, \"tracking_information.pkl\"), \"wb\"),\n",
    ")\n",
    "print(\"The training process has done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
